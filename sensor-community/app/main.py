import logging
import sys
import os
import json
import time
import datetime
from datetime import timedelta, timezone

# –ò–º–ø–æ—Ä—Ç—ã –º–æ–¥—É–ª–µ–π (–æ–Ω–∏ –¥–æ–ª–∂–Ω—ã –ª–µ–∂–∞—Ç—å —Ä—è–¥–æ–º)
from scraper import scrape_data
from processor import run_processing
from uploader import run_upload

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s [%(levelname)s] %(message)s',
    handlers=[logging.StreamHandler(sys.stdout)]
)


def load_config():
    # –ü—É—Ç—å –∫ –∫–æ–Ω—Ñ–∏–≥—É –≤–Ω—É—Ç—Ä–∏ –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–∞
    config_path = 'config.json'

    # –ü—ã—Ç–∞–µ–º—Å—è –Ω–∞–π—Ç–∏ –∫–æ–Ω—Ñ–∏–≥
    if os.path.exists(config_path):
        with open(config_path, 'r', encoding='utf-8') as f:
            config = json.load(f)
    elif os.path.exists('app/config.json'):  # Fallback –¥–ª—è –ª–æ–∫–∞–ª—å–Ω–æ–≥–æ –∑–∞–ø—É—Å–∫–∞
        with open('app/config.json', 'r', encoding='utf-8') as f:
            config = json.load(f)
    else:
        config = {}

    # –ü–µ—Ä–µ–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∏–∑ ENV (–¥–ª—è Docker)
    env_token = os.getenv('MAPBOX_TOKEN')
    if env_token:
        config['mapbox_token'] = env_token

    env_frost = os.getenv('FROST_URL')
    if env_frost:
        config['frost_url'] = env_frost

    # –ü—É—Ç—å –∫ –¥–∞–Ω–Ω—ã–º (–≤ Docker volume —ç—Ç–æ /data)
    if 'data_dir' not in config:
        config['data_dir'] = '/data'

    return config


# --- –ù–û–í–ê–Ø –§–£–ù–ö–¶–ò–Ø: –£–º–Ω—ã–π –ø–∞—Ä—Å–∏–Ω–≥ –¥–∞—Ç—ã ---
def parse_date(date_str):
    """–ü—ã—Ç–∞–µ—Ç—Å—è —Ä–∞—Å–ø–∞—Ä—Å–∏—Ç—å –¥–∞—Ç—É –≤ —Ä–∞–∑–Ω—ã—Ö —Ñ–æ—Ä–º–∞—Ç–∞—Ö."""
    if not date_str:
        return None

    formats = [
        "%Y-%m-%d",  # 2025-09-30 (ISO)
        "%d.%m.%Y",  # 30.09.2025 (Russian/German)
        "%Y/%m/%d"  # 2025/09/30
    ]

    for fmt in formats:
        try:
            return datetime.datetime.strptime(date_str, fmt).date()
        except ValueError:
            continue

    raise ValueError(f"–ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç –¥–∞—Ç—ã: {date_str}. –û–∂–∏–¥–∞–µ—Ç—Å—è YYYY-MM-DD –∏–ª–∏ DD.MM.YYYY")


# --- –†–ê–ë–û–¢–ê –°–û STATE-–§–ê–ô–õ–û–ú ---

def get_state_file_path(config):
    data_dir = config.get('data_dir', '/data')
    os.makedirs(data_dir, exist_ok=True)
    return os.path.join(data_dir, 'state.json')


def load_state(state_path):
    if not os.path.exists(state_path):
        return {}
    try:
        with open(state_path, 'r', encoding='utf-8') as f:
            return json.load(f)
    except Exception as e:
        logging.error(f"Error reading state file: {e}")
        return {}


def save_state(state_path, state):
    try:
        with open(state_path, 'w', encoding='utf-8') as f:
            json.dump(state, f, indent=4, ensure_ascii=False)
    except Exception as e:
        logging.error(f"Error saving state file: {e}")


def prepare_schedule_and_state(config, current_state):
    new_state = current_state.copy()
    at_least_one_task = False

    # –î–ª—è —Ä–∞—Å—á–µ—Ç–∞ 'auto' (–≤—á–µ—Ä–∞—à–Ω–∏–π –¥–µ–Ω—å)
    today = datetime.datetime.now().date()

    for s_type in ['sds', 'bme']:
        if s_type not in config.get('sensors', {}):
            continue
        if s_type not in new_state:
            new_state[s_type] = {}

        for sensor_id, dates in config['sensors'][s_type].items():
            start_cfg = dates.get('start')
            end_cfg = dates.get('end')

            sensor_id_str = str(sensor_id)
            sensor_state = new_state[s_type].get(sensor_id_str, {})
            last_downloaded = sensor_state.get('last_downloaded')

            # --- –õ–æ–≥–∏–∫–∞ START ---
            if last_downloaded:
                # –ï—Å–ª–∏ —É–∂–µ –∫–∞—á–∞–ª–∏, –±–µ—Ä–µ–º —Å–ª–µ–¥—É—é—â—É—é –¥–∞—Ç—É –ø–æ—Å–ª–µ –ø–æ—Å–ª–µ–¥–Ω–µ–π —É—Å–ø–µ—à–Ω–æ–π
                last_date = parse_date(last_downloaded)
                calc_start = last_date + timedelta(days=1)
            else:
                # –ï—Å–ª–∏ –ø–µ—Ä–≤—ã–π —Ä–∞–∑, –±–µ—Ä–µ–º –¥–∞—Ç—É –∏–∑ –∫–æ–Ω—Ñ–∏–≥–∞
                calc_start = parse_date(start_cfg)

            # --- –õ–æ–≥–∏–∫–∞ END ---
            if end_cfg == 'auto':
                # 'auto' –∑–Ω–∞—á–∏—Ç –ø–æ –≤—á–µ—Ä–∞—à–Ω–∏–π –¥–µ–Ω—å (–∞—Ä—Ö–∏–≤—ã –ø–æ—è–≤–ª—è—é—Ç—Å—è —Å –∑–∞–¥–µ—Ä–∂–∫–æ–π)
                calc_end = today - timedelta(days=1)
            else:
                calc_end = parse_date(end_cfg)

            # --- –ü—Ä–æ–≤–µ—Ä–∫–∞ –∑–∞–¥–∞—á–∏ ---
            if calc_start <= calc_end:
                at_least_one_task = True

                # –û–±–Ω–æ–≤–ª—è–µ–º –∫–æ–Ω—Ñ–∏–≥ –≤ –ø–∞–º—è—Ç–∏ (–ø–µ—Ä–µ–≤–æ–¥–∏–º –≤ ISO —Ñ–æ—Ä–º–∞—Ç –¥–ª—è —Å–∫—Ä–∞–ø–µ—Ä–∞)
                config['sensors'][s_type][sensor_id]['start'] = str(calc_start)
                config['sensors'][s_type][sensor_id]['end'] = str(calc_end)

                # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º —Å—Ç–µ–π—Ç (–∫–∞–∫ –±—É–¥—Ç–æ –≤—Å—ë —Å–∫–∞—á–∞–ª–æ—Å—å —É—Å–ø–µ—à–Ω–æ)
                sensor_state['last_downloaded'] = str(calc_end)
                sensor_state['last_run_timestamp'] = datetime.datetime.now().isoformat()
                new_state[s_type][sensor_id_str] = sensor_state
            else:
                # –ó–∞–¥–∞—á–∞ –≤—ã–ø–æ–ª–Ω–µ–Ω–∞, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º
                pass

    return config, new_state, at_least_one_task


def job():
    logging.info("üöÄ Job started.")
    try:
        config = load_config()
        state_path = get_state_file_path(config)
        current_state = load_state(state_path)

        config, pending_state, has_tasks = prepare_schedule_and_state(config, current_state)

        # 1. SCRAPING
        if has_tasks:
            scrape_data(config)
            # –í–ê–ñ–ù–û: –°–æ—Ö—Ä–∞–Ω—è–µ–º —Å—Ç–µ–π—Ç, —á—Ç–æ–±—ã –Ω–µ –∫–∞—á–∞—Ç—å –æ–¥–Ω–æ –∏ —Ç–æ –∂–µ
            save_state(state_path, pending_state)
        else:
            logging.info("üí§ Skipping scrape (everything up to date).")

        # 2. PROCESSING
        run_processing(config)

        # 3. UPLOADING
        run_upload(config)

        logging.info("üèÅ Job finished successfully.")

    except Exception as e:
        logging.exception(f"üî• Critical error in main job: {e}")


def main_loop():
    # –ó–∞–≥—Ä—É–∂–∞–µ–º –∫–æ–Ω—Ñ–∏–≥, —á—Ç–æ–±—ã —É–∑–Ω–∞—Ç—å –∏–Ω—Ç–µ—Ä–≤–∞–ª
    config = load_config()
    interval_seconds = config.get('load_interval')
    interval_minutes = interval_seconds / 60

    logging.info(f"Service started. Schedule: every {interval_minutes:.2f} minutes.")

    # –ù–µ–±–æ–ª—å—à–∞—è –ø–∞—É–∑–∞ –ø—Ä–∏ —Å—Ç–∞—Ä—Ç–µ
    time.sleep(5)

    while True:
        job()
        logging.info(f"Waiting {interval_minutes:.2f} minutes for next run...")
        time.sleep(interval_seconds)


if __name__ == '__main__':
    sys.stdout.reconfigure(encoding='utf-8')
    main_loop()